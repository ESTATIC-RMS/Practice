{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5cd4351-ddf7-48d8-9e52-dc6fa00fef6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7e42e9-153d-4bda-8ecd-d1e9adf9a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2017cbef-31c1-455e-a170-a190cda8c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Normalize the pixel values to [0, 1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b6cc020-bd56-4091-99e7-292fd8150517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. One-hot encode the labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a44dec01-9156-4187-be4b-bec783073eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sharj\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "Flatten(input_shape=(28, 28)), # Flatten 28x28 images into 784 input neurons\n",
    "Dense(128, activation='relu'), # Hidden layer with 128 neurons\n",
    "Dense(64, activation='relu'), # Another hidden layer\n",
    "Dense(10, activation='softmax') # Output layer with 10 classes (digits 0-9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e161e077-6f5f-48fa-b65b-049b2766de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "\n",
    "loss='categorical_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a86fe92-9cf7-4745-b2b4-949ab1680010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 14ms/step - accuracy: 0.8594 - loss: 0.4804 - val_accuracy: 0.9588 - val_loss: 0.1364\n",
      "Epoch 2/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9654 - loss: 0.1148 - val_accuracy: 0.9655 - val_loss: 0.1138\n",
      "Epoch 3/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9791 - loss: 0.0716 - val_accuracy: 0.9687 - val_loss: 0.1069\n",
      "Epoch 4/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.9826 - loss: 0.0548 - val_accuracy: 0.9730 - val_loss: 0.0936\n",
      "Epoch 5/5\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0411 - val_accuracy: 0.9736 - val_loss: 0.0994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2dcf6055be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0e64c2-38d0-4b4a-a47f-5b4e50998a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9707 - loss: 0.1037\n",
      "Test Accuracy: 0.9740\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb8c930b-6d2d-4633-af03-71b738da9f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e69b706f-48fb-4439-b8c3-d5f7a8525228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one image from the test set\n",
    "index = 0 # you can change this to test different images\n",
    "image = x_test[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "889d2644-d4ff-4f09-9c2f-8dc1ea289602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show the image\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.title(\"Input Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a66a98dc-1f43-4c7a-836a-58f41dbc14b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image for prediction (reshape and scale if needed)\n",
    "image_reshaped = image.reshape(1, 28, 28) # Shape: (1, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bce4533-7f5a-4ea2-b075-631d709d7536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
      "[[2.5084784e-08 1.2200585e-08 6.7389765e-06 2.9840687e-05 4.2642286e-11\n",
      "  5.8565687e-11 1.7891342e-13 9.9995697e-01 2.4336762e-08 6.4523801e-06]]\n",
      "Predicted digit: 7\n"
     ]
    }
   ],
   "source": [
    "# Predict the class\n",
    "predicted_probabilities = model.predict(image_reshaped)\n",
    "print(predicted_probabilities)\n",
    "predicted_class = np.argmax(predicted_probabilities)\n",
    "print(f\"Predicted digit: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335eaaf-5eca-4a29-9b31-9868bbcb9477",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
