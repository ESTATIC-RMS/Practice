{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":1003830,"datasetId":550917,"databundleVersionId":1032543,"isSourceIdPinned":false}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:48:26.064871Z","iopub.execute_input":"2025-07-07T14:48:26.065731Z","iopub.status.idle":"2025-07-07T14:48:28.478514Z","shell.execute_reply.started":"2025-07-07T14:48:26.065692Z","shell.execute_reply":"2025-07-07T14:48:28.477640Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"shaunthesheep/microsoft-catsvsdogs-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:48:50.693560Z","iopub.execute_input":"2025-07-07T14:48:50.693860Z","iopub.status.idle":"2025-07-07T14:48:54.646123Z","shell.execute_reply.started":"2025-07-07T14:48:50.693835Z","shell.execute_reply":"2025-07-07T14:48:54.645279Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/microsoft-catsvsdogs-dataset\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:49:52.380654Z","iopub.execute_input":"2025-07-07T14:49:52.381010Z","iopub.status.idle":"2025-07-07T14:50:11.210212Z","shell.execute_reply.started":"2025-07-07T14:49:52.380978Z","shell.execute_reply":"2025-07-07T14:50:11.209254Z"}},"outputs":[{"name":"stderr","text":"2025-07-07 14:49:54.584643: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751899794.846129      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751899794.921199      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"data_dir = \"/kaggle/input/microsoft-catsvsdogs-dataset\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:52:34.860616Z","iopub.execute_input":"2025-07-07T14:52:34.861316Z","iopub.status.idle":"2025-07-07T14:52:34.865573Z","shell.execute_reply.started":"2025-07-07T14:52:34.861286Z","shell.execute_reply":"2025-07-07T14:52:34.864541Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Normalize pixel values (0‚Äì255 ‚Üí 0‚Äì1)\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2  # 20% for validation\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:52:51.289007Z","iopub.execute_input":"2025-07-07T14:52:51.289693Z","iopub.status.idle":"2025-07-07T14:52:51.293785Z","shell.execute_reply.started":"2025-07-07T14:52:51.289662Z","shell.execute_reply":"2025-07-07T14:52:51.292895Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Training generator\ntrain_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary',\n    subset='training'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:52:59.845573Z","iopub.execute_input":"2025-07-07T14:52:59.846089Z","iopub.status.idle":"2025-07-07T14:53:42.745894Z","shell.execute_reply.started":"2025-07-07T14:52:59.846056Z","shell.execute_reply":"2025-07-07T14:53:42.745018Z"}},"outputs":[{"name":"stdout","text":"Found 20000 images belonging to 1 classes.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Validation generator\nval_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:54:48.651277Z","iopub.execute_input":"2025-07-07T14:54:48.652172Z","iopub.status.idle":"2025-07-07T14:55:01.440813Z","shell.execute_reply.started":"2025-07-07T14:54:48.652143Z","shell.execute_reply":"2025-07-07T14:55:01.439826Z"}},"outputs":[{"name":"stdout","text":"Found 5000 images belonging to 1 classes.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"model = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n    MaxPooling2D(2,2),\n    \n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    \n    Conv2D(128, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n\n    Flatten(),\n    Dense(512, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:56:30.728762Z","iopub.execute_input":"2025-07-07T14:56:30.729113Z","iopub.status.idle":"2025-07-07T14:56:31.023009Z","shell.execute_reply.started":"2025-07-07T14:56:30.729088Z","shell.execute_reply":"2025-07-07T14:56:31.022042Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n2025-07-07 14:56:30.744593: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:56:41.417296Z","iopub.execute_input":"2025-07-07T14:56:41.418143Z","iopub.status.idle":"2025-07-07T14:56:41.433186Z","shell.execute_reply.started":"2025-07-07T14:56:41.418110Z","shell.execute_reply":"2025-07-07T14:56:41.432210Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    epochs=5,\n    validation_data=val_data\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-07T14:56:53.107469Z","iopub.execute_input":"2025-07-07T14:56:53.107781Z","iopub.status.idle":"2025-07-07T14:59:11.884852Z","shell.execute_reply.started":"2025-07-07T14:56:53.107759Z","shell.execute_reply":"2025-07-07T14:59:11.883702Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m152/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m6:58\u001b[0m 884ms/step - accuracy: 0.9816 - loss: 0.0259","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3243383521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mkeras_symbolic_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_is_keras_symbolic_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeras_symbolic_tensors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x78f909220220>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3532, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x78f909220220>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_2147]"],"ename":"UnknownError","evalue":"Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nUnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x78f909220220>\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 248, in _finite_generator\n    yield self._standardize_batch(self.py_dataset[i])\n                                  ~~~~~~~~~~~~~~~^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/usr/local/lib/python3.11/dist-packages/PIL/Image.py\", line 3532, in open\n    raise UnidentifiedImageError(msg)\n\nPIL.UnidentifiedImageError: cannot identify image file <_io.BytesIO object at 0x78f909220220>\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_multi_step_on_iterator_2147]","output_type":"error"}],"execution_count":11},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='Train Accuracy')\nplt.plot(history.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"Accuracy\")\nplt.legend()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\nimg = image.load_img('path_to_test_image.jpg', target_size=(150, 150))\nimg_array = image.img_to_array(img)\nimg_array = img_array / 255.0\nimg_array = np.expand_dims(img_array, axis=0)\n\nprediction = model.predict(img_array)\n\nif prediction[0][0] > 0.5:\n    print(\"It's a dog üê∂\")\nelse:\n    print(\"It's a cat üê±\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}